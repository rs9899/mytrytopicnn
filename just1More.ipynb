{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def cleaner(str):\n",
    "    soup = BeautifulSoup(str)\n",
    "    str1 = soup.get_text()\n",
    "    str1 = str1.replace('\\\\n', ' ')\n",
    "    str2 = str1.replace(\"\\\\\",\"\") # str2 = str1.replace(\"\\\\\",\" \") # remove non-ascii???\n",
    "    str3 = str2.replace(\"(\",\" \")\n",
    "    str4 = str3.replace(\")\",\" \")\n",
    "    str5 = re.sub(\"[0-9]|\\.|{|}|\\^|;|=|/|'\" , \" \", str4)\n",
    "    return str5\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 400000 word vectors.\n",
      "Processing text dataset\n",
      "12959\n",
      "15540\n",
      "14284\n",
      "12498\n",
      "Found 42101 unique tokens.\n",
      "('Shape of data tensor:', (55281, 1000))\n",
      "('Shape of label tensor:', (55281, 4))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "BASE_DIR = '../'\n",
    "GLOVE_DIR = os.path.join(BASE_DIR, 'glove.6B')\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt')) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "# second, prepare text samples and their labels\n",
    "print('Processing text dataset')\n",
    "\n",
    "\n",
    "df = pandas.read_csv('test2.csv' , low_memory=False)\n",
    "d = df.to_dict()\n",
    "\n",
    "docs = []\n",
    "labels = []\n",
    "for key2 in d['conceptCode/0']:\n",
    "\tif pandas.isna(d['conceptCode/0'][key2]) or pandas.isna(d['content/0/solutionContent'][key2]) or pandas.isna(d['content/0/questionContent'][key2]) :\n",
    "\t\tpass\n",
    "\telse:\n",
    "\t\tlabl = cleaner(d['conceptCode/0'][key2]).rstrip()\n",
    "\t\tif (labl == \"P\"):\n",
    "\t\t\tlabels.append(0)\n",
    "\t\telif (labl == \"C\"):\n",
    "\t\t\tlabels.append(1)\n",
    "\t\telif (labl == \"M\") :\n",
    "\t\t\tlabels.append(2)\n",
    "\t\telse : # Current others label ;; Like miscellaneous\n",
    "\t\t\tlabels.append(3)\n",
    "\n",
    "\t\t# Need some good string parsing here\n",
    "\t\tstrin = cleaner(d['content/0/solutionContent'][key2]) + \" \" + cleaner(d['content/0/questionContent'][key2])\n",
    "\t\tdocs.append( strin )\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "print(labels.count(0))\n",
    "print(labels.count(1))\n",
    "print(labels.count(2))\n",
    "print(labels.count(3))\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(docs)\n",
    "sequences = tokenizer.texts_to_sequences(docs)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = labels[:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = labels[-num_validation_samples:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing embedding matrix.\n",
      "u'searle\\u2019s'\n",
      "u'\\xa0one'\n",
      "u'\\u21d2xge'\n",
      "u'are\\xa0'\n",
      "u'\\xd7pleft'\n",
      "u'dyright'\n",
      "u'hclmathrel'\n",
      "u'\\xa0friday\\xa0'\n",
      "u'professionalcityprofessionabhubaneshwarpharmacistbhyderbadprofessorcmumbaiartistdbangaloreengineereahmedabadlawyerfchennaidoctorgjaipurcounsellor'\n",
      "u'tonoplast'\n",
      "u'equation\\xa0of'\n",
      "u'hchoxrightarrow'\n",
      "u'food\\u2019'\n",
      "u'\\u2013oh'\n",
      "u'solutionright'\n",
      "u'ixy'\n",
      "u'rqp'\n",
      "u'bsqrt'\n",
      "u'\\xa0\\xa0force'\n",
      "u'negativethinmathspace'\n",
      "u'following\\xa0'\n",
      "u'tan\\xa0'\n",
      "u'e\\xd7'\n",
      "u'friction\\xa0'\n",
      "u'product\\xa0'\n",
      "u'\\u201ct\\u201d'\n",
      "u'dtimes'\n",
      "u'rtleft'\n",
      "u'there\\u2019'\n",
      "u's\\u2019p'\n",
      "u'millicurie'\n",
      "u'pteridophyta'\n",
      "u'saraswativijayam'\n",
      "u\"q'\"\n",
      "u'brownright'\n",
      "u'oxright'\n",
      "u'abcabc\\u2026'\n",
      "u'y\\xe2\\xb1'\n",
      "u\"mv'\"\n",
      "u'x\\xa0'\n",
      "u\"avogadro's\"\n",
      "u'rrightarrow'\n",
      "u'ikfm'\n",
      "u'xln'\n",
      "u'epropto'\n",
      "u'ii\\xa0'\n",
      "u'\\xa0iv'\n",
      "u'isspace'\n",
      "u'officerfqclerkgpresearch'\n",
      "u'beena\\u2019s'\n",
      "u'\\xa0\\xa0s'\n",
      "u'abqr'\n",
      "u'sulphates'\n",
      "u'balpha'\n",
      "u'eadcb'\n",
      "u'\\xe2\\xb1left'\n",
      "u'iright'\n",
      "u'\\xa0hangs'\n",
      "u'ktimesfrac'\n",
      "u'statements\\xa0is'\n",
      "u'voso'\n",
      "u'borazine'\n",
      "u'pwidehat'\n",
      "u'ocy'\n",
      "u'msdelta'\n",
      "u'\\xe2\\u2021\\u2019c'\n",
      "u'\\xa0ke\\xa0'\n"
     ]
    }
   ],
   "source": [
    "# In[20]:\n",
    "\n",
    "\n",
    "print('Preparing embedding matrix.')\n",
    "\n",
    "# prepare embedding matrix\n",
    "i1 = 0\n",
    "j = 0\n",
    "\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        i1 = i1 + 1\n",
    "    else:\n",
    "        j = j + 1\n",
    "        if j % 100 == 0:\n",
    "            print(repr(word))\n",
    "        embedding_matrix[i] = np.random.random_sample((100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6799\n"
     ]
    }
   ],
   "source": [
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13201\n"
     ]
    }
   ],
   "source": [
    "print(i1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Preparing embedding matrix.\n",
    "searle’s\n",
    " one\n",
    "⇒xge\n",
    "are \n",
    "×pleft\n",
    "dyright\n",
    "hclmathrel\n",
    " friday \n",
    "professionalcityprofessionabhubaneshwarpharmacistbhyderbadprofessorcmumbaiartistdbangaloreengineereahmedabadlawyerfchennaidoctorgjaipurcounsellor\n",
    "tonoplast\n",
    "equation of\n",
    "hchoxrightarrow\n",
    "food’\n",
    "–oh\n",
    "solutionright\n",
    "ixy\n",
    "rqp\n",
    "bsqrt\n",
    "  force\n",
    "negativethinmathspace\n",
    "following \n",
    "tan \n",
    "e×\n",
    "friction \n",
    "product \n",
    "“t”\n",
    "dtimes\n",
    "rtleft\n",
    "there’\n",
    "s’p\n",
    "millicurie\n",
    "pteridophyta\n",
    "saraswativijayam\n",
    "q'\n",
    "brownright\n",
    "oxright\n",
    "abcabc…\n",
    "yâ±\n",
    "mv'\n",
    "x \n",
    "avogadro's\n",
    "rrightarrow\n",
    "ikfm\n",
    "xln\n",
    "epropto\n",
    "ii \n",
    " iv\n",
    "isspace\n",
    "officerfqclerkgpresearch\n",
    "beena’s\n",
    "  s\n",
    "abqr\n",
    "sulphates\n",
    "balpha\n",
    "eadcb\n",
    "â±left\n",
    "iright\n",
    " hangs\n",
    "ktimesfrac\n",
    "statements is\n",
    "voso\n",
    "borazine\n",
    "pwidehat\n",
    "ocy\n",
    "msdelta\n",
    "â‡’c\n",
    " ke "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
